{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-FP: Pipelines\n",
    "\n",
    "A very useful concept in functional programming is a pipeline. Pipelines compose individual steps together and form one big function. The output of one function gets fed into the next function.\n",
    "\n",
    "Start to think of data as being on an assembly line of specialized machines instead of on a workbench with a list of instructions. Henry Ford saw the power of this idea and became the father of mass production. The same 100 year-old insight can apply to your data\n",
    "\n",
    "Source: https://medium.com/@hansonkd/thinking-functionally-with-python-and-django-4127e3ace6e9\n",
    "\n",
    "## Chaining Calls\n",
    "Surprisingly, Python does not have anything that is similar for building iterators. Lets take an example where a generator of CSV rows gets convert ed to Book objects, filtered by year, sorted and finally formatted. It quickly gets unweildy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = get_book_row_generator_from_csv('mybooks.csv')\n",
    "formatted_books = list(\n",
    "    map(\n",
    "        sorted(\n",
    "            filter(\n",
    "                map(\n",
    "                    books,\n",
    "                    Book.from_row\n",
    "                ),\n",
    "                lambda: book.year >= 1950\n",
    "            ),\n",
    "            key=lambda book: (book.year, book.author_name.lower())\n",
    "        ),\n",
    "        '{0.title} | {0.author} ({0.year})'.format\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major problem with this syntax is that the first action is the deepest in the nest. It’s not how a person thinks.\n",
    "\n",
    "Expressing iterator transformation by chaining together functions would be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = get_book_row_generator_from_csv('mybooks.csv')\n",
    "\n",
    "formatted_books = (\n",
    "    conduit(books)\n",
    "        .map(Book.from_row)\n",
    "        .filter(lambda book: book.year >= 1950)\n",
    "        .sort(lambda book: (book.year, book.author_name.lower()))\n",
    "        .map('{0.title} | {0.author} ({0.year})'.format)\n",
    "        .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conduit class is dead simple. If you want more robust features, there is PyFunctional and even an underscore.js port which does the same thing and much more.\n",
    "\n",
    "The conduit isn’t a performance upgrade, but it expresses data transformation in a clear, natural way.\n",
    "\n",
    "## Function Composition\n",
    "Function composition is a pipeline technique that pieces together small functions into a larger function. It is very similar to chaining, except the end result is a function and not a result.\n",
    "\n",
    "Chaining method calls is actually doing something very similar to function composition. Remember that obj.method() it is the same as ObjClass.method(obj)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obj(object):\n",
    "    def method1(self):\n",
    "        return do_stuff(self)\n",
    "\n",
    "    def method2(self):\n",
    "        return do_other_stuff(self)\n",
    "\n",
    "    def method3(self):\n",
    "        return do_more_stuff(self)\n",
    "\n",
    "result = Obj().method1().method2().method3()\n",
    "\n",
    "# Equivalent using function composition.\n",
    "\n",
    "def compose(*funcs):\n",
    "    return lambda xx: reduce(lambda val, func: func(val), reversed(funcs), xx)\n",
    "\n",
    "composed = compose(\n",
    "   Obj.method1,\n",
    "   Obj.method2,\n",
    "   Obj.method3\n",
    ")\n",
    "result2 = composed(Obj())\n",
    "\n",
    "assert result == result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using composition, each method is explicit. Using dot notation and chaining, if any method in the chain returns a subclass class of Obj that subclassses’ method is used. In Python we frequently want to turn everything into a Class, but sometimes it is simpler and better to use small, freestanding functions. Function composition helps to give some of the power of classes with the simplicity of compact functions.\n",
    "\n",
    "## The Flat Data Pipeline\n",
    "In the case of our report needs to be explicit. Our report consists of pulling Django objects which represents financial securities and doing computations on them. Django objects are dangereous. Query counts can explode unexpectedly. Since we wanted to pull all data upfront, passing Django objects to Excel view is not an option. We need to flatten the data before it gets to the view. The view should only deal with strings, decimals, namedtuples, and other basic python objects.\n",
    "\n",
    "Our first attempt was a pipeline of functions which took two element tuple: the “flat” object and the Django model instance. It copied over everything that the Excel writer needed from the model to the flat object. This ensured that it was impossible to make a query while writing the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_securities = Security.objects.filter(company=company).for_report().iterator()\n",
    "\n",
    "def flatten(*args):\n",
    "    def transform_pipeline(mdl):\n",
    "        data = FlatData()\n",
    "        for fn in args:\n",
    "            fn(data, mdl)\n",
    "        return data\n",
    "    return transform_pipeline\n",
    "\n",
    "def add_issue_date(flat, mdl):\n",
    "    flat.issue_date = mdl.get_issue_date()\n",
    "\n",
    "def add_label(flat, mdl):\n",
    "    flat.label = mdl.get_label()\n",
    "\n",
    "flat_securities = (\n",
    "  conduit(all_securities)\n",
    "      ...\n",
    "      .map(\n",
    "          flatten(\n",
    "              add_issue_date,\n",
    "              add_label\n",
    "          )\n",
    "      )\n",
    "      ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it isn’t a purely functional approach, recognizing the strengths and weaknesses of the language can lead to cleaner code. Don’t swim upstream trying to achieve theoretical, immutable perfection in a mutable world.\n",
    "\n",
    "## Efficient Pipes\n",
    "If the report is simple, the data can be directly piped into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file_output.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['Label', 'Issue Date'])\n",
    "    \n",
    "    for security in flat_securities:\n",
    "        writer.write_row({'Label': security.label, 'Issue Date': security.issue_date})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `iterator()` to pull data from the database makes the steps simple: read a row from the database, transform that row through the pipeline, and then write the data to a CSV. Then repeat for the next row. It’s an incredibly efficient way to write a report. Only keep one row is kept in memory and the roles of each piece of code are clearly defined.\n",
    "\n",
    "## Pure, Higher-Order Functions and Resource Management\n",
    "Unfortunately, not all reports are that simple. Usually the transform step requires information not found directly on the element it is transforming. The problem areas we identitied were clarity and resource management.\n",
    "\n",
    "Using classes invites complexity. It also makes it difficult to tell if a function is pure. A pure function is a function that when run with the same input will always give the same output. This means no database access, no cache access and even no clock access. The result is higher-order functions which conveniently document their requirements and everything is explicit.\n",
    "\n",
    "For example, a transformer that relies on the current export time to tell if a security is canceled or not, needs the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_canceled(report_date)\n",
    "    def inner(flat, mdl):\n",
    "        flat.is_canceled = mdl.canceled_date < report_date\n",
    "    return inner\n",
    "\n",
    "report_date = datetime.today()\n",
    "\n",
    "flat_securities = (\n",
    "  conduit(all_securities)\n",
    "      .map(\n",
    "          flatten(\n",
    "              ...\n",
    "              is_canceled(report_date),\n",
    "          )\n",
    "      )\n",
    "      ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the transformation provides its own documentation and informs us that in order to know if a security is canceled or not, an external resource not contained on the Django object is needed.\n",
    "\n",
    "This becomes especially important for database access. Some of the transformations for securities depend on other securities. We wanted to make it a goal to only have one copy of each object in memory. Using `select_related` and `prefetch_related` won’t help us here.\n",
    "\n",
    "Instead of using `iterator()` to load the data, we load every piece of data into lists. Then create indexes to the data using basic python dictionaries. It’s fast, efficient, and requires no dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computations.py\n",
    "\n",
    "def add_shareholder_name(shareholder_ix):\n",
    "    def inner(flat, mdl):\n",
    "        flat.shareholder_name = shareholder_ix[mdl.shareholder_id]\n",
    "    return inner\n",
    "\n",
    "def add_transfered_to_labels(transfered_to_ix):\n",
    "    def inner(flat, mdl):\n",
    "        flat.exercised_from_labels = [\n",
    "            sec.label for sec in transfered_to_ix[mdl.id]\n",
    "        ]\n",
    "    return inner\n",
    "\n",
    "...\n",
    "# data.py\n",
    "\n",
    "all_securities = list(Security.objects.filter(company=company).all())\n",
    "all_shareholders = list(ShareHolders.objects.filter(company=company).all())\n",
    "\n",
    "# Many to One\n",
    "shareholder_ix = {sh.pk: sh for shareholder in all_shareholders}\n",
    "# Reverse foreign key\n",
    "transfered_to_ix = defaultdict(list)\n",
    "for security in all_securities:\n",
    "    if security.transformed_from_id:\n",
    "        transfered_to_ix[security.transformed_from_id].append(security)\n",
    "\n",
    "flat_securities = (\n",
    "  conduit(all_securities)\n",
    "      ...\n",
    "      .filter(should_show_security) #  Filter securities since now we grab all of them\n",
    "      .map(\n",
    "          flatten(\n",
    "              ...\n",
    "              add_shareholder_name(shareholder_ix),\n",
    "              add_transfered_to_labels(transfered_to_ix)\n",
    "          )\n",
    "      )\n",
    "      ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all of the transformation functions are isolated, an assert statement to the flatten function can be added to be absolutely certain there are no queries during the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db import connection\n",
    "\n",
    "def flatten(*args):\n",
    "    def transform_pipeline(mdl):\n",
    "        data = FlatData()\n",
    "        num_before = len(connection.queries)\n",
    "        for fn in args:\n",
    "            fn(data, mdl)\n",
    "        assert len(connection.queries) == num_before\n",
    "        return data\n",
    "    return transform_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Thoughts\n",
    "Everything that we built required no external dependencies. The glue, classes and support functions were only a few lines each. We were able to build a powerful data pipeline by taking advantage of the native features of Python.\n",
    "\n",
    "We learned some important lessons:\n",
    "\n",
    "1. Break your process into discrete steps.\n",
    "2. Have one copy of data in memory.\n",
    "3. Embrace Python’s OOP and functional styles. Don’t go for purity.\n",
    "4. Make it as simple as possible. Rely on the standard lib.\n",
    "5. Focus on a solid foundation. Save optimizations till the end.\n",
    "6. Don’t be afraid to throw code away or comporomise.\n",
    "\n",
    "The results are dramatic. From exponentially growing query counts reaching up to 7,000 for a single report down to about 30 and generation times for some customers dropped from 600 seconds to 15 seconds. Now, it is easier to detect were the performance problems are. Separating the different stages allows us to see OpenPyxl’s styles cause a 2x performance drop and which transformations are expensive. Those have not been optimized yet.\n",
    "\n",
    "Our code is faster, cleaner and even more resuable. Since the code is broken into distinct parts, there is nothing stopping us from piping the Data to a JSON API instead of to an Excel document.\n",
    "\n",
    "Software design is only one component of the problem. The reports run on worker servers and are processed through a queue system. Improving them is a cross-domain effort. By optimizing other parts of the system, we believe we can get all reports down to 5 seconds or less. These are things that can be optimized now that we have a solid foundation.\n",
    "\n",
    "Functional programming didn’t do anything magical. All it did was bring clarity and structure to a complex process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
