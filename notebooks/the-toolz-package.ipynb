{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyFP - The `toolz` Package\n",
    "\n",
    "## Overview\n",
    "Toolz provides a set of utility functions for iterators, functions, and dictionaries. These functions interoperate well and form the building blocks of common data analytic operations. They extend the standard libraries itertools and functools and borrow heavily from the standard libraries of contemporary functional languages.\n",
    "\n",
    "Toolz provides a suite of functions which have the following functional virtues:\n",
    "\n",
    "* Composable: They interoperate due to their use of core data structures.\n",
    "* Pure: They don’t change their inputs or rely on external state.\n",
    "* Lazy: They don’t run until absolutely necessary, allowing them to support large streaming data sets.\n",
    "\n",
    "Toolz functions are pragmatic. They understand that most programmers have deadlines.\n",
    "\n",
    "* Low Tech: They’re just functions, no syntax or magic tricks to learn\n",
    "* Tuned: They’re profiled and optimized\n",
    "* Serializable: They support common solutions for parallel computing\n",
    "\n",
    "This gives developers the power to write powerful programs to solve complex problems with relatively simple code. This code can be easy to understand without sacrificing performance. Toolz enables this approach, commonly associated with functional programming, within a natural Pythonic style suitable for most developers.\n",
    "\n",
    "## Related documents\n",
    "* github: https://github.com/pytoolz/toolz\n",
    "* docs: https://toolz.readthedocs.io/en/latest/\n",
    "\n",
    "## How to get it up and running\n",
    "You may need to setup your python virtual environment and pip install.\n",
    "\n",
    "```\n",
    "$ mkdir project\n",
    "$ cd project\n",
    "$ virtuanenv .env\n",
    "$ source .env/bin/activate\n",
    "(.env) $ pip install toolz\n",
    "\n",
    "```\n",
    "\n",
    "## Import into project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples from docs\n",
    "\n",
    "## Function Purity\n",
    "We call a function pure if it meets the following criteria\n",
    "\n",
    "1. It does not depend on hidden state, or equivalently it only depends on its inputs.\n",
    "2. Evaluation of the function does not cause side effects\n",
    "\n",
    "In short the internal work of a pure function is isolated from the rest of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pure function\n",
    "def min(x, y):\n",
    "    if x < y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "# An impure function\n",
    "exponent = 2\n",
    "\n",
    "def powers(L):\n",
    "    for i in range(len(L)):\n",
    "        L[i] = L[i]**exponent\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State\n",
    "Impure functions are often more efficient but also require that the programmer “keep track” of the state of several variables. Keeping track of this state becomes increasingly difficult as programs grow in size. By eschewing state programmers are able to conceptually scale out to solve much larger problems. The loss of performance is often negligible compared to the freedom to trust that your functions work as expected on your inputs.\n",
    "\n",
    "Maintaining state provides efficiency at the cost of surprises. Pure functions produce no surprises and so lighten the mental load of the programmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laziness\n",
    "\n",
    "Lazy iterators evaluate only when necessary. They allow us to semantically manipulate large amounts of data while keeping very little of it actually in memory. They act like lists but don’t take up space.\n",
    "\n",
    "Example - A Tale of Two Cities\n",
    "We open a file containing the text of the classic text “A Tale of Two Cities” by Charles Dickens [link](http://www.gutenberg.org/files/98/98-0.txt).\n",
    "\n",
    "```python\n",
    ">>> book = open('tale-of-two-cities.txt')\n",
    ">>> next(book)\n",
    "\"It was the best of times,\"\n",
    "\n",
    ">>> next(book)\n",
    "\"it was the worst of times,\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation\n",
    "We can lazily operate on lazy iterators without doing any actual computation. For example lets read the book in upper case\n",
    "\n",
    "```python\n",
    ">>> from toolz import map  # toolz' map is lazy by default\n",
    ">>> loud_book = map(str.upper, book)\n",
    ">>> next(loud_book)\n",
    "\"IT WAS THE AGE OF WISDOM,\"\n",
    ">>> next(loud_book)\n",
    "\"IT WAS THE AGE OF FOOLISHNESS,\"\n",
    "```\n",
    "\n",
    "It is as if we applied the function str.upper onto every line of the book; yet the first line completes instantaneously. Instead Python does the uppercasing work only when it becomes necessary, i.e. when you call next to ask for another line.\n",
    "\n",
    "## Reductions\n",
    "You can operate on lazy iterators just as you would with `lists`, `tuples`, or `sets`. You can use them in for loops as in\n",
    "\n",
    "``` python\n",
    "for line in loud_book:\n",
    "    ...\n",
    "```    \n",
    "You can instantiate them all into memory by calling them with the constructors `list`, or `tuple`.\n",
    "``` python\n",
    "loud_book = list(loud_book)\n",
    "```\n",
    "\n",
    "Of course if they are very large then this might be unwise. Often we use laziness to avoid loading large datasets into memory at once. Many computations on large datasets don’t require access to all of the data at a single time. In particular reductions (like sum) often take large amounts of sequential `data(like[1, 2, 3, 4])` and produce much more manageable results (like 10) and can do so just by viewing the data a little bit at a time. For example we can count all of the letters in the Tale of Two Cities trivially using functions from `toolz`\n",
    "\n",
    "``` python\n",
    ">>> from toolz import concat, frequencies\n",
    ">>> letters = frequencies(concat(loud_book))\n",
    "{ 'A': 48036,\n",
    "  'B': 8402,\n",
    "  'C': 13812,\n",
    "  'D': 28000,\n",
    "  'E': 74624,\n",
    "  ...\n",
    " ```\n",
    " In this case frequencies is a sort of reduction. At no time were more than a few hundred bytes of Tale of Two Cities necessarily in memory. We could just have easily done this computation on the entire Gutenberg collection or on Wikipedia. In this case we are limited by the size and speed of our hard drive and not by the capacity of our memory.\n",
    "\n",
    "## Control Flow\n",
    "Programming is hard when we think simultaneously about several concepts. Good programming breaks down big problems into small problems and builds up small solutions into big solutions. By this practice the need for simultaneous thought is restricted to only a few elements at a time.\n",
    "\n",
    "All modern languages provide mechanisms to build data into data structures and to build functions out of other functions. The third element of programming, besides data and functions, is control flow. Building complex control flow out of simple control flow presents deeper challenges.\n",
    "\n",
    "Each element in a computer program is either\n",
    "\n",
    "* A variable or value literal like `x`, `total`, or `5`\n",
    "* A function or computation like the `+` in `x + 1`, the function `fib` in `fib(3)`, the method split in `line.split(',')`, or the `=` in `x = 0`\n",
    "* Control flow like `if`, `for`, or `return`\n",
    "\n",
    "Here is a piece of code; see if you can label each term as either variable/value, function/computation, or control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    a, b = 0, 1\n",
    "    for i in range(n):\n",
    "        a, b = b, a + b\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming is hard when we have to juggle many code elements of each type at the same time. Good programming is about managing these three elements so that the developer is only required to think about a handful of them at a time. For example we might collect many integer variables into a list of integers or build a big function out of smaller ones. While we have natural ways to manage data and functions, control flow presents more of a challenge.\n",
    "\n",
    "We organize our data into **data structures** like lists, dictionaries, or objects in order to group related data together – this allows us to manipulate large collections of related data as if we were only manipulating a single entity.\n",
    "\n",
    "We **build large functions out of smaller ones**; enabling us to break up a complex task like doing laundry into a sequence of simpler tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_laundry(clothes):\n",
    "    wet_clothes = wash(clothes, coins)\n",
    "    dry_clothes = dry(wet_clothes, coins)\n",
    "    return fold(dry_clothes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control flow is more challenging; how do we break down complex control flow into simpler pieces that fit in our brain? How do we encapsulate commonly recurring patterns?\n",
    "\n",
    "Lets motivate this with an example of a common control structure, applying a function to each element in a list. Imagine we want to download the HTML source for a number of webpages.\n",
    "\n",
    "``` python\n",
    "from urllib import request\n",
    "\n",
    "urls = ['http://www.google.com', 'http://www.wikipedia.com', 'http://www.apple.com']\n",
    "html_texts = []\n",
    "for item in urls:\n",
    "    html_texts.append(request.urlopen(item))\n",
    "return html_texts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or maybe we want to compute the Fibonacci numbers on a particular set of integers\n",
    "\n",
    "``` python\n",
    "integers = [1, 2, 3, 4, 5]\n",
    "fib_integers = []\n",
    "for item in integers:\n",
    "    fib_integers.append(fib(item))\n",
    "return fib_integers\n",
    "```\n",
    "\n",
    "These two unrelated applications share an identical control flow pattern. They apply a function (urlopen or fib) onto each element of an input list (urls, or integers), appending the result onto an output list. Because this control flow pattern is so common we give it a name, map, and say that we map a function (like urlopen) onto a list (like urls).\n",
    "\n",
    "Because Python can treat functions like variables we can encode this control pattern into a higher-order-function as follows:\n",
    "\n",
    "```python\n",
    "def map(function, sequence):\n",
    "    output = []\n",
    "    for item in sequence:\n",
    "        output.append(function(item))\n",
    "    return output\n",
    "```\n",
    "\n",
    "This allows us to simplify our code above to the following, pithy solutions\n",
    "\n",
    "\n",
    "``` python\n",
    "html_texts = map(urlopen, urls)\n",
    "fib_integers = map(fib, integers)\n",
    "```\n",
    "\n",
    "Experienced Python programmers know that this control pattern is so popular that it has been elevated to the status of syntax with the popular list comprehension\n",
    "\n",
    "``` python\n",
    "html_texts = [urlopen(url) for url in urls]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currying\n",
    "Traditionally partial evaluation of functions is handled with the `partial` higher order function from `functools`. Currying provides syntactic sugar.\n",
    "\n",
    "``` python\n",
    ">>> from functools import partial\n",
    ">>> double = partial(mul, 2)    # Partial evaluation\n",
    ">>> doubled = double(2)         # Currying\n",
    "```\n",
    "\n",
    "This syntactic sugar is valuable when developers chain several higher order functions together.\n",
    "\n",
    "Often when composing smaller functions to form big ones we need partial evaluation. \n",
    "\n",
    "In general.\n",
    "``` python\n",
    ">>> def f(x, y, z):\n",
    "...     # Do stuff with x, y, and z\n",
    "\n",
    ">>> # partially evaluate f with known values a and b\n",
    ">>> def g(z):\n",
    "...     return f(a, b, z)\n",
    "\n",
    ">>> # partially evaluate f with known values a and b\n",
    ">>> g = partial(f, a, b)\n",
    "```\n",
    "\n",
    "In this context currying is just syntactic sugar for partial evaluation. A curried function partially evaluates if it does not receive enough arguments to compute a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from toolz import curry\n",
    "\n",
    "@curry              # We can use curry as a decorator\n",
    "def mul(x, y):\n",
    "    return x * y\n",
    "\n",
    "double = mul(2)     # mul didn't receive enough arguments to evaluate\n",
    "                    # so it holds onto the 2 and waits, returning a\n",
    "                    # partially evaluated function, double\n",
    "print(double(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Analytics\n",
    "The toolz functions can be composed to analyze large streaming datasets. Toolz supports common analytics patterns like the selection, grouping, reduction, and joining of data through pure composable functions. These functions often have analogs to familiar operations in other data analytics platforms like SQL or Pandas.\n",
    "\n",
    "Throughout this document we’ll use this simple dataset of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = [(1, 'Alice', 100, 'F'),  # id, name, balance, gender\n",
    "            (2, 'Bob', 200, 'M'),\n",
    "            (3, 'Charlie', 150, 'M'),\n",
    "            (4, 'Dennis', 50, 'M'),\n",
    "            (5, 'Edith', 300, 'F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting with `map` and `filter`\n",
    "\n",
    "Simple projection and linear selection from a sequence is achieved through the standard functions `map` and `filter`.\n",
    "\n",
    "``` sql\n",
    "SELECT name, balance\n",
    "FROM accounts\n",
    "WHERE balance > 150;\n",
    "```\n",
    "\n",
    "These functions correspond to the SQL commands `SELECT` and `WHERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bob', 200), ('Edith', 300)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolz.curried import pipe, map, filter, get\n",
    "pipe(accounts, filter(lambda acc: acc[2] > 150),\n",
    "               map(get([1, 2])),\n",
    "               list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split-apply-combine with `groupby` and `reduceby`\n",
    "We separate split-apply-combine operations into the following two concepts\n",
    "\n",
    "1. Split the dataset into groups by some property\n",
    "2. Reduce each of the groups with some synopsis function\n",
    "\n",
    "Toolz supports this common workflow with\n",
    "\n",
    "1. a simple in-memory solution\n",
    "2. a more sophisticated streaming solution.\n",
    "\n",
    "### In Memory Split-Apply-Combine\n",
    "The in-memory solution depends on the functions groupby to split, and valmap to apply/combine.\n",
    "\n",
    "``` sql\n",
    "SELECT gender, SUM(balance)\n",
    "FROM accounts\n",
    "GROUP BY gender;\n",
    "```\n",
    "\n",
    "We first show these two functions piece by piece to show the intermediate groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': [(1, 'Alice', 100, 'F'), (5, 'Edith', 300, 'F')],\n",
       " 'M': [(2, 'Bob', 200, 'M'), (3, 'Charlie', 150, 'M'), (4, 'Dennis', 50, 'M')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolz import groupby, valmap, compose\n",
    "from toolz.curried import get, pluck\n",
    "\n",
    "groupby(get(3), accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': 400, 'M': 400}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valmap(compose(sum, pluck(2)),_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Split-Apply-Combine\n",
    "The groupby function collects the entire dataset in memory into a dictionary. While convenient, the groupby operation is not streaming and so this approach is limited to datasets that can fit comfortably into memory.\n",
    "\n",
    "Toolz achieves streaming split-apply-combine with reduceby, a function that performs a simultaneous reduction on each group as the elements stream in. To understand this section you should first be familiar with the builtin function reduce.\n",
    "\n",
    "The reduceby operation takes a key function, like `get(3)` or `lambda x: x[3]`, and a binary operator like `add` or `lesser = lambda acc, x: acc if acc < x else x`. \n",
    "\n",
    "It successively applies the key function to each item in succession, accumulating running totals for each key by combining each new value with the previous using the binary operator. It can’t accept full reduction operations like sum or min as these require access to the entire group at once. Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 4, True: 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolz import reduceby\n",
    "\n",
    "def iseven(n):\n",
    "    return n % 2 == 0\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "reduceby(iseven, add, [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The even numbers are added together `(2 + 4 = 6)` into group `True`, and the odd numbers are added together `(1 + 3 = 4)` into group False.\n",
    "\n",
    "Note that we have to replace the reduction sum with the binary operator add. The incremental nature of add allows us to do the summation work as new data comes in. The use of binary operators like add over full reductions like sum enables computation on very large streaming datasets.\n",
    "\n",
    "The challenge to using reduceby often lies in the construction of a suitable binary operator. Here is the solution for our accounts example that adds up the balances for each group:\n",
    "\n",
    "```python\n",
    ">>> binop = lambda total, account: total + account[2]\n",
    ">>> reduceby(get(3), binop, accounts, 0)\n",
    "{'F': 400, 'M': 400}\n",
    "```\n",
    "\n",
    "This construction supports datasets that are much larger than available memory. Only the output must be able to fit comfortably in memory and this is rarely an issue, even for very large split-apply-combine computations.\n",
    "\n",
    "## Semi-Streaming join\n",
    "We register multiple datasets together with join. Consider a second dataset storing addresses by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [(1, '123 Main Street'),  # id, address\n",
    "             (2, '5 Adams Way'),\n",
    "             (5, '34 Rue St Michel')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join this dataset against our accounts dataset by specifying attributes which register different elements with each other; in this case they share a common first column, id.\n",
    "\n",
    "```sql\n",
    "SELECT accounts.name, addresses.address\n",
    "FROM accounts, addresses\n",
    "WHERE accounts.id = addresses.id;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alice', '123 Main Street')\n",
      "('Bob', '5 Adams Way')\n",
      "('Edith', '34 Rue St Michel')\n"
     ]
    }
   ],
   "source": [
    "from toolz import join, first\n",
    "\n",
    "result = join(first, accounts,\n",
    "              first, addresses)\n",
    "\n",
    "for ((id, name, bal, gender), (id, address)) in result:\n",
    "    print((name, address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join takes four main arguments, a left and right key function and a left and right sequence. It returns a sequence of pairs of matching items. In our case the return value of join is a sequence of pairs of tuples such that the first element of each tuple (the ID) is the same. In the example above we unpack this pair of tuples to get the fields that we want (`name` and `address`) from the result.\n",
    "\n",
    "## Join on arbitrary functions / data\n",
    "\n",
    "Those familiar with SQL are accustomed to this kind of join on columns. However a functional join is more general than this; it doesn’t need to operate on tuples, and key functions do not need to get particular columns. In the example below we match numbers from two collections so that exactly one is even and one is odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 7), (4, 7), (1, 8), (3, 8), (2, 9), (4, 9)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iseven(x):\n",
    "    return x % 2 == 0\n",
    "def isodd(x):\n",
    "    return x % 2 == 1\n",
    "\n",
    "list(join(iseven, [1, 2, 3, 4],\n",
    "          isodd, [7, 8, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Streaming Join\n",
    "The Toolz Join operation fully evaluates the left sequence and streams the right sequence through memory. Thus, if streaming support is desired the larger of the two sequences should always occupy the right side of the join.\n",
    "\n",
    "## Algorithmic Details\n",
    "The semi-streaming join operation in toolz is asymptotically optimal. Computationally it is linear in the size of the input + output. In terms of storage the left sequence must fit in memory but the right sequence is free to stream.\n",
    "\n",
    "The results are not normalized, as in SQL, in that they permit repeated values. If normalization is desired, consider composing with the function unique (note that unique is not fully streaming.)\n",
    "\n",
    "## More Complex Example\n",
    "The accounts example above connects two one-to-one relationships, accounts and addresses; there was exactly one name per ID and one address per ID. This need not be the case. The join abstraction is sufficiently flexible to join one-to-many or even many-to-many relationships. The following example finds city/person pairs where that person has a friend who has a residence in that city. This is an example of joining two many-to-many relationships, because a person may have many friends and because a friend may have many residences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alice', 'Berlin')\n",
      "('Alice', 'Paris')\n",
      "('Alice', 'Shanghai')\n",
      "('Edith', 'Chicago')\n",
      "('Edith', 'NYC')\n",
      "('Zhao', 'Chicago')\n",
      "('Zhao', 'NYC')\n",
      "('Zhao', 'Berlin')\n",
      "('Zhao', 'Paris')\n"
     ]
    }
   ],
   "source": [
    "friends = [('Alice', 'Edith'),\n",
    "           ('Alice', 'Zhao'),\n",
    "           ('Edith', 'Alice'),\n",
    "           ('Zhao', 'Alice'),\n",
    "           ('Zhao', 'Edith')]\n",
    "\n",
    "cities = [('Alice', 'NYC'),\n",
    "          ('Alice', 'Chicago'),\n",
    "          ('Dan', 'Syndey'),\n",
    "          ('Edith', 'Paris'),\n",
    "          ('Edith', 'Berlin'),\n",
    "          ('Zhao', 'Shanghai')]\n",
    "\n",
    "# Vacation opportunities\n",
    "# In what cities do people have friends?\n",
    "result = join(second, friends,\n",
    "              first, cities)\n",
    "\n",
    "for ((name, friend), (friend, city)) in sorted(unique(result)):\n",
    "    print((name, city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join is computationally powerful:\n",
    "\n",
    "It is expressive enough to cover a wide set of analytics operations\n",
    "It runs in linear time relative to the size of the input and output\n",
    "Only the left sequence must fit in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips and Tricks\n",
    "Toolz functions can be combined to make functions that, while common, aren’t a part of toolz’s standard library. This section presents a few of these recipes.\n",
    "\n",
    "### `keyjoin(leftkey, leftseq, rightkey, rightseq)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import starmap\n",
    "from toolz import join, merge\n",
    "\n",
    "def keyjoin(leftkey, leftseq, rightkey, rightseq):\n",
    "    return starmap(merge, join(leftkey, leftseq, rightkey, rightseq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'name': 'Karan',\n",
       "  'location': 'San Francisco',\n",
       "  'person_id': 1,\n",
       "  'hobby': 'Tennis'},\n",
       " {'id': 1,\n",
       "  'name': 'Karan',\n",
       "  'location': 'San Francisco',\n",
       "  'person_id': 1,\n",
       "  'hobby': 'Acting'},\n",
       " {'id': 2,\n",
       "  'name': 'Matthew',\n",
       "  'location': 'Oakland',\n",
       "  'person_id': 2,\n",
       "  'hobby': 'Biking'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = [{'id': 0, 'name': 'Anonymous Guy', 'location': 'Unknown'},\n",
    "          {'id': 1, 'name': 'Karan', 'location': 'San Francisco'},\n",
    "          {'id': 2, 'name': 'Matthew', 'location': 'Oakland'}]\n",
    "hobbies = [{'person_id': 1, 'hobby': 'Tennis'},\n",
    "           {'person_id': 1, 'hobby': 'Acting'},\n",
    "           {'person_id': 2, 'hobby': 'Biking'}]\n",
    "\n",
    "list(keyjoin('id', people, 'person_id', hobbies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
